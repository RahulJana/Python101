{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simaple FFN architecture:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForwardNetwork():\n",
    "    def __init__(self) -> None:\n",
    "        self.w1 = np.random.rand()  # x1 -> node1\n",
    "        self.w2 = np.random.rand()  # x2 -> node1\n",
    "        self.b1 = 0  # bias1 -> node1\n",
    "\n",
    "        self.w3 = np.random.rand()  # x1 -> node2\n",
    "        self.w4 = np.random.rand()  # x2 -> node2\n",
    "        self.b2 = 0  # bias2 -> node2\n",
    "        \n",
    "        self.w5 = np.random.rand()  # node1 -> node3\n",
    "        self.w6 = np.random.rand()  # node2 -> node3\n",
    "        self.b3 = 0  # bias3 -> node3\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        return 1.0/(1.0 + np.exp(-x))\n",
    "    \n",
    "    def forward_pass(self, x):\n",
    "        self.x1, self.x2 = x\n",
    "\n",
    "        # Neuron 1\n",
    "        self.a1 = self.w1 * self.x1 + self.w2 * self.x2 + self.b1\n",
    "        self.h1 = self.sigmoid(self.a1)\n",
    "\n",
    "        # Neuron 2\n",
    "        self.a2 = self.w3 * self.x1 + self.w4 * self.x2 + self.b2\n",
    "        self.h2 = self.sigmoid(self.a2)\n",
    "\n",
    "        # Neuron 3\n",
    "        self.a3 = self.w5 * self.h1 + self.w6 * self.h2 + self.b3\n",
    "        self.h3 = self.sigmoid(self.a3)\n",
    "\n",
    "        return self.h3  # returns y\n",
    "    \n",
    "    def grad(self, x, y):\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : _type_\n",
    "            _description_\n",
    "        y : _type_\n",
    "            _description_\n",
    "        \"\"\"\n",
    "        self.forward_pass(x)\n",
    "\n",
    "        self.dw5 = (self.h3 - y) * self.h3 * (1 - self.h3) * self.h1\n",
    "        self.dw6 = (self.h3 - y) * self.h3 * (1 - self.h3) * self.h2\n",
    "        self.db3 = (self.h3 - y) * self.h3 * (1 - self.h3)\n",
    "\n",
    "        self.dw1 = (self.h3 - y) * self.h3 * (1 - self.h3) * self.w5 * self.h1 * (1 - self.h1) * self.x1\n",
    "        self.dw2 = (self.h3 - y) * self.h3 * (1 - self.h3) * self.w5 * self.h1 * (1 - self.h1) * self.x2\n",
    "        self.db1 = (self.h3 - y) * self.h3 * (1 - self.h3) * self.w5 * self.h1 * (1 - self.h1)\n",
    "\n",
    "        self.dw3 = (self.h3 - y) * self.h3 * (1 - self.h3) * self.w6 * self.h2 * (1 - self.h2) * self.x1\n",
    "        self.dw4 = (self.h3 - y) * self.h3 * (1 - self.h3) * self.w6 * self.h2 * (1 - self.h2) * self.x2\n",
    "        self.db2 = (self.h3 - y) * self.h3 * (1 - self.h3) * self.w6 * self.h2 * (1 - self.h2)\n",
    "    \n",
    "    def fit(self, X, Y, epochs = 1, learning_rate = 1, initialize = True, display_loss = False):\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : _type_\n",
    "            _description_\n",
    "        Y : _type_\n",
    "            _description_\n",
    "        epochs : int, optional\n",
    "            _description_, by default 1\n",
    "        learning_rate : int, optional\n",
    "            _description_, by default 1\n",
    "        initialize : bool, optional\n",
    "            _description_, by default True\n",
    "        display_loss : bool, optional\n",
    "            _description_, by default False\n",
    "        \"\"\"\n",
    "        if initialize:\n",
    "            self.w1 = np.random.rand()  # x1 -> node1\n",
    "            self.w2 = np.random.rand()  # x2 -> node1\n",
    "            self.b1 = 0  # bias1 -> node1\n",
    "\n",
    "            self.w3 = np.random.rand()  # x1 -> node2\n",
    "            self.w4 = np.random.rand()  # x2 -> node2\n",
    "            self.b2 = 0  # bias2 -> node2\n",
    "            \n",
    "            self.w5 = np.random.rand()  # node1 -> node3\n",
    "            self.w6 = np.random.rand()  # node2 -> node3\n",
    "            self.b3 = 0  # bias3 -> node3\n",
    "        \n",
    "        if display_loss:\n",
    "            loss = {}\n",
    "        \n",
    "        for i in tqdm(range(epochs), total=epochs, unit=\"epoch\"):\n",
    "            dw1, dw2, dw3, dw4, dw5, dw6, db1, db2, db3 = [0] * 9\n",
    "            for x, y in zip(X, Y):\n",
    "                self.grad(x, y)\n",
    "                \n",
    "                dw1 += self.dw1\n",
    "                dw2 += self.dw2\n",
    "                \n",
    "                dw3 += self.dw3\n",
    "                dw4 += self.dw4\n",
    "                \n",
    "                dw5 += self.dw5\n",
    "                dw6 += self.dw6\n",
    "                \n",
    "                db1 += self.db1\n",
    "                db2 += self.db2\n",
    "                db3 += self.db3\n",
    "            \n",
    "            m = X.shape[1]\n",
    "            self.w1 -= learning_rate * dw1 / m\n",
    "            self.w2 -= learning_rate * dw2 / m\n",
    "            \n",
    "            self.w3 -= learning_rate * dw3 / m\n",
    "            self.w4 -= learning_rate * dw4 / m\n",
    "            \n",
    "            self.w5 -= learning_rate * dw5 / m\n",
    "            self.w6 -= learning_rate * dw6 / m\n",
    "            \n",
    "            self.b1 -= learning_rate * db1 / m\n",
    "            self.b2 -= learning_rate * db2 / m\n",
    "            self.b3 -= learning_rate * db3 / m\n",
    "\n",
    "            def predict(self, X):\n",
    "                Y_pred = []\n",
    "                for x in X:\n",
    "                    y_pred = self.forward_pass(x)\n",
    "                    Y_pred.append(y_pred)\n",
    "                    return np.array(Y_pred)\n",
    "\n",
    "            if display_loss:\n",
    "                Y_pred = self.predict(X)\n",
    "                loss[i] = mean_squared_error(Y_pred, Y)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "guvi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
